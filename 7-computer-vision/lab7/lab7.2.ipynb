{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets.mnist as mnist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: .\n",
       "    Split: Train"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.MNIST('.', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs = {'batch_size': 64}\n",
    "test_kwargs = {'batch_size': 1000}\n",
    "dataset1 = mnist.MNIST('.', train=True, transform=T.ToTensor())\n",
    "dataset2 = mnist.MNIST('.', train=False, transform=T.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301912\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.357258\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.104665\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.252001\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.117704\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.233640\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.036674\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.201668\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.190179\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.175451\n",
      "\n",
      "Test set: Average loss: 0.0568, Accuracy: 9829/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.043467\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.097622\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.028796\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.135394\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.040372\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.126412\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.085305\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.097112\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.120595\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.119237\n",
      "\n",
      "Test set: Average loss: 0.0432, Accuracy: 9863/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.119416\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.177892\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.098012\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.124663\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.051217\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.038714\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.165395\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.098423\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.132184\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.074774\n",
      "\n",
      "Test set: Average loss: 0.0405, Accuracy: 9866/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.078925\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.079509\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.035178\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.088423\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.104847\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.075106\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.077560\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.069258\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.114887\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.066839\n",
      "\n",
      "Test set: Average loss: 0.0327, Accuracy: 9894/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Net()\n",
    "optimizer = optim.Adadelta(model.parameters())\n",
    "\n",
    "for epoch in range(1,5):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2[42][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x278b914cf40>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABHElEQVR4nM2PsUtCYRTFf4a8qaIgCQmapKAgGiKnoCFocMkhHNsSokFamgpqCmpoqGgRGpsiIqHobyhfRaSjkBgkD0IdSo42vHzvZTy3oLvcy/nd893vwB9X313el/XfKteB1Xf94I506McGTFmjfvC+g5GG3iO/1YDdmg0rZE8j3QCP9R/ONwDmLsuSpJvNYdfZaFohoOc6SrbyVJ6cNwon265zD2BfOu0FWH2WPM+aAGfSjC2kJOhq4aH2r+Y90PiOkmwJW85aUnpdhPBGsZqZBUgr5cBgVvbVtaKqCRirKO5eCEufRxFg6iBTu1p50VLAyUkgsT5BrZAGjOk4D7FS04WwEI2N21Puwjz/AC+E4OAyAMel9lj/pb4A5MBr19Xwy5EAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = T.ToPILImage()(dataset2[54][0])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6637e+01, -2.3055e+01, -2.7066e+01, -2.7932e+01, -2.1231e+01,\n",
       "         -1.0692e+01, -2.2888e-05, -3.1402e+01, -1.6947e+01, -2.5722e+01]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "reaction = model(T.ToTensor()(img).unsqueeze(0))\n",
    "reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction.argmax()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Маємо 6, як і має бути"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b5bea0e812b9422d8280180d75bbf9a3028a87b011419c246d3d1a055740d27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
