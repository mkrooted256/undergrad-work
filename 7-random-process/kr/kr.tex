% !TEX program = xelatex
% !TEX encoding = UTF-8

\documentclass[11pt, a4paper]{article} % use larger type; default would be 10pt

\usepackage{fontspec} % Font selection for XeLaTeX; see fontspec.pdf for documentation
\defaultfontfeatures{Mapping=tex-text} % to support TeX conventions like ``---''
\usepackage{xunicode} % Unicode support for LaTeX character names (accents, European chars, etc)
\usepackage{xltxtra} % Extra customizations for XeLaTeX
\usepackage{tikz}
\usetikzlibrary{arrows,calc,patterns}

\setmainfont[Ligatures=TeX]{[EBGaramond-Regular.ttf]} % set the main body font (\textrm), assumes Charis SIL is installed
%\setsansfont{Deja Vu Sans}
\setmonofont[Ligatures=TeX]{[FiraCode-Regular.ttf]}

% other LaTeX packages.....
\usepackage{fullpage}
\usepackage[top=2cm, bottom=4.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd,systeme}
\usepackage{unicode-math}
\usepackage{cancel}
\geometry{a4paper} 
%\usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{multicol}

\renewcommand\lstlistingname{Algorithm}
\renewcommand\lstlistlistingname{Algorithms}
\def\lstlistingautorefname{Alg.}
\lstdefinestyle{mystyle}{
    % backgroundcolor=\color{backcolour},   
    % commentstyle=\color{codegreen},
    % keywordstyle=\color{magenta},
    % numberstyle=\tiny\color{codegray},
    % stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

\newcommand\course{7 - Випадкові процеси}
\newcommand\hwnumber{Залікова робота}             % <-- homework number
\newcommand\idgroup{ФІ-91}                
\newcommand\idname{Михайло Корешков}  

\usepackage[framemethod=TikZ]{mdframed}
\mdfsetup{%
	backgroundcolor = black!5,
}
\mdfdefinestyle{ans}{%
    backgroundcolor = green!5,
    linecolor = green!50,
    linewidth = 1pt,
}

\pagestyle{fancyplain}
\headheight 35pt
\lhead{\idgroup \\ \idname}
\chead{\textbf{\Large \hwnumber}}
\rhead{\course \\ \today}
\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\linespread{1.2}

\DeclareMathOperator{\cov}{cov}


\begin{document}

\section*{№1}
\begin{mdframed}
    Алгебра циліндричних множин. Теорема Колмогорова про існування процесу.
\end{mdframed}

Теорема Колмогорова стверджує, що для довільної сім'ї узгоджених ймовірнісних мір 
$$\left\{\mu_{t_1...t_n}, \; t_i \in T\right\}$$
існує випадковий процес такий, що ці міри будуть його відповідними скінченновимірними розподілами
$$P\left(\left(X(t_1), ..., X(t_n)\right)\in B\right) = \mu_{t_1,...,t_n}(B)$$.

Тобто, якщо задати розподіл, що має сенс, то для нього знайдеться процес.

Узгоджена сім'я - це така, у якій 
\begin{itemize}
    \item порядок аргументів міри відповідає порядку індексів міри (задається через перестановки за фіксованої множини $\{t_1,...,t_n\}$)
    \item задання всієї $\mathbb R$ у якості одного з аргументів еквівалентно прибиранню цього аргумента разом з відповідним індексом. 
    Це потрібно, щоб показати, що $P(X(t)\in\mathbb R)=1$.
\end{itemize}

Суть теореми в тому, щоб довести, що вираз $A = \left(X(t_1), ..., X(t_n)\right)\in B$ можна трактувати як 
елемент певної $\sigma$-алгебри.
Тоді $P(A)$ буде природнім чином рівною мірі елемента $A$ в цій алгебрі. 

Множини вигляду $A$ називають Циліндричними.

Циліндрична множина - це множина вигляду 
\[C = \left\{x \in X  \;|\; x_{i} \in A_i ,\; i=\overline{1,n}\right\}\]
\[X = Y_1 \times ... \times Y_n, \quad x_i \in Y_i,\quad A_i \subset Y_i\]

У нашому випадку циліндричні множини нас цікавлять у контексті скінченновимірних розподілів
випадкового процесу. 

Процес (дійснозначний) $\left(X_t, t\in T\right)$ - це просто деяка функція з $T$ в $\mathbb R$ з обмеженнями, накладеними розподілом. 
Тобто, $X \in \mathbb{R}^T$. 
Тоді вважаючи $A_1 \times ... \times A_n = B \in \mathcal B(\mathbb R^n), \quad i \to t_i$ 
Матимемо
\[C_{t_1...t_n}(B) = \left\{X \in \mathbb{R}^T \;|\; (X(t_1), ..., X(t_n)) \in B\right\}\]

Множини $C$ утворюють алгебру:
\begin{itemize}
    \item 
    \(C_t(\mathbb R) = \mathbb{R}^T = \Omega,\; \text{очевидно}\)
    \item
    \(C_{t_1...t_n}(B)^C = \left\{X \in \mathbb{R}^T \;|\; \neg \left( (X(t_1), ..., X(t_n)) \in B\right)\right\} = \left\{X \in \mathbb{R}^T \;|\; (X(t_1), ..., X(t_n)) \in B^C\right\} =\) \\
    \(= C_{t_1...t_n}(B^C) \in \mathcal A\)
    \item
    \(C_{t_1...t_k}(B_1) \cup C_{t_{k+1}...t_n}(B_2) = C_{t_1...t_k...t_n}(B_1 \times \mathbb R^{n-k})\cup C_{t_1...t_k...t_n}(\mathbb R^k \times B_2) = \) \\
    \(= C_{t_1...t_n}(B_1 \cup B_2) \in \mathcal A\)
    \item (+ узгодженість)
\end{itemize}


На цій алгебрі родина $\mu$ буде коректною адитивною мірою.
Далі доводимо, що $\mu$ буде однозначно продовжуватись на $\sigma$-алгебру, породжену множинами $C$.

В результаті отримуємо, що $\left(\Omega=\mathbb{R}^T, \sigma(\left\{C\right\})=\mathcal F, \mu = P\right)$ - це ймовірнісний простір, 
на якому $X_t : \mathbb{R}^T \to \mathbb R$ (значення процесу в час $t$) буде випадковою величиною, що залежать від результату $\omega \in \Omega$, 
а $C$ будуть подіями вигляду "значення процесу в часи $t_1..t_n$ потрапили в множини $B_1...B_n$". 

$\omega \in \Omega$ - це параметр, за яким "обирається" конкретна реалізація процесу.

Скінченновимірні розподіли процесу тоді будуть за побудовою рівні початковій мірі.


\section*{№2}
\begin{mdframed}
    Iснування i єдинiсть iнварiантного розподiлу ланцюга Маркова у випадку коли всi стани
сполучаються i додатнi.
\end{mdframed}

$(X_n, \; n\in \mathbb N)$ - ланцюг Маркова якщо
\[x_{n+1} = f(x_n, \varepsilon_n)\]
, $X_n \in E, \; f : E\times\mathbb R \to E$
Інакше, 
\[P(X_{n+1} = j \;|\; X_{n} = i) = P(i,j,n)\]
\[P(X_{n+1} = j \;|\; X_{1} = i_1, ..., X_{n} = i_n) = P(i_n,j,n)\]

Ланцюг однорідний, якщо ці величини не залежать від $n$:
\[P(X_{n+1} = j \;|\; X_{n} = i) = P(i,j) = P_{ij}\]

Інваріантний розподіл $\pi$ на $E$ для однорідного ланцюга із матрицею перехідних ймовірностей $P$ - це такий, що 
\[P(X_0 = i) = \pi_i\] 
\[P(X_n = i) = \left.\left(\pi P^n\right)\right|_i = \pi_i\]
Тобто
\[\pi P = \pi\]

Стан $j$ досяжний із $i$, якщо з $i$ можна перейти в $j$ із ненульовою ймовірністю (для хоч деякої кількості кроків).

Стани $i, j$ сполучні, якщо з одного в інший та навпаки можна перейти із ненульовою ймовірністю (для хоч деякої кількості кроків).  

Стан, з якого інші досяжні, але який сам є недосяжним, називається несуттєвим (бо з певного моменту ланцюг з нього вийде та ніколи не повернеться). 

Наприклад, при $p = \begin{pmatrix}
    0.5 & 0.5 \\ 0 & 1
\end{pmatrix}$ маємо стан 2 досяжний із 1, але стан 1 недосяжний зі стану 2 
(ланцюг застрягне в стані 2). Ці стани не є сполучними. Стан 1 є несуттєвим.


При $p = \begin{pmatrix}
    0 & 1 & 0 \\ 
    0 & 0 & 1 \\
    1 & 0 & 0
\end{pmatrix}$ маємо ланцюг, в якому всі стани досяжні один з одного (якщо не за один, то за два кроки).

Якщо всі стани ланцюга сполучні між собою (сполучність, до речі, це відношення еквівалентності), то ланцюг називають нерозкладним.

Також можна досліджувати час між візитами станів у ланцюгу та середній час, який ланцюг проводить в кожному стані.

Якщо ланцюг нерозкладний та всі стани у деякому сенсі "асиптотично суттєві", то для нього існуватиме інваріантний розподіл.

Введемо статистики
\[s_{j} = s_j(1) = \inf\{n\ge 1 : X_n = j\}\]
\[s_{j}(m+1) = \inf\{n\ge s_j(m) : X_n = j\}\]
По суті, $\{s_j, s_j(2), s_j(3), ...\}$ - це послідовність всіх моментів часу, в яких ланцюг був у стані $j$.

Позначатимемо $P(A \;|\; X_0=i) =: P_i(A)$ та аналогічно $M_i$.

Стан $j$ \textbf{додатний}, якщо в середньому ланцюг в нього регулярно повертається:
\[M_js_j < \infty\]

Стан $j$ \textbf{нульовий}, якщо в середньому ланцюг в нього не повертається (та сама "асимптотична несуттєвість")
\[M_js_j = \infty\]

Назви "нульовий" та "додатний" походять від того, що середня доля часу $T_i$ перебування в стані $i$ буде як раз $\frac{1}{M_is_i}$.
Тобто він буде нульовим для нульових станів та додатним для додатних.

Можна довести, що для нерозкладного ланцюга з лише додатними станами
\[P^n_{jj} \underset{abel}{\longrightarrow} \frac{1}{M_j s_j}\]
\[P^n_{ij} \underset{abel}{\longrightarrow} \frac{P_i(\exists n\ge 1 \;:\; X_n = j)}{M_j s_j}\]

А звідси можна отримати асимптоту ймовірності знайти ланцюг в кожному стані.  
Це і буде інваріантним розподілом $\pi$ ланцюга.
\begin{itemize}
    \item $\pi_i = \frac{1}{M_i s_i}$
    \item Інваріантний розподіл $\pi$ - єдиний 
\end{itemize}

Інваріантні розподіли зазвичай шукаються розв'язком рівняння $\pi = \pi P$. 

Що також цікаво, інваріантний розподіл буде власним вектором матриці $P$ з власним числом $1$ - 
це можна використовувати для його обчислення на комп'ютерах.  


\section*{№3}
\begin{mdframed}
    \[\tau \sim U[0;1]\]
    \[X(t) = t-\tau-k, \quad t\in[\tau+k,\tau+k+1], \; k\in\mathbb Z\]

    Перевірити неперервність та неперервну диференційовність в середньо квадратичному сенсі.
\end{mdframed}


Можна переписати визначення процесу наступним чином
\[X(t) = \{t-\tau\} = (t-\tau) - \lfloor t-\tau\rfloor\]

\begin{align*}
    MX(t) &= \int_0^1 \{t-x\} dx = \int_0^1 \{\lfloor t \rfloor + \{t\} - x\} dx = \\
    &= \int_0^{\{t\}} (\{t\}-x) dx + \int_{\{t\}}^1 (\{t\}-x+1)dx = \frac{\{t\}^2}{2} + \frac{1-\{t\}^2}{2} = \frac{1}{2}
\end{align*}

\begin{align*}
    MX^2(t) &= \int_0^1 \{t-x\}^2 dx = \text{насправді це просто інтеграл за періодом} = \int_{0}^{1} \{1-x\}^2dx = \\
    &= \int_0^1 (1-x)^2dx = \left.-\frac{(1-x)^3}{3}\right|_0^1 = \frac{1}{3}
\end{align*}

\[DX(t) = MX^2 - (MX)^2 = \frac{1}{3} - \frac{1}{4} = \frac{1}{12}\]

\subsection*{1. Неперервність}
Визначення неперервності в $L_2$:
\[\lim_{dt \to 0} \|X(t+dt)-X(t)\| = \lim_{dt\to 0 }M\left|X(t+dt)-X(t)\right|^2 = 0\]

Одразу подивимося на окіл проблемних точок $\{\tau+k,\; k\in\mathbb Z\}$.
Процес має період 1, отже розглядатиму лише одну точку, наприклад $k=0$.

% \begin{align*}
%     M\left|X(\tau+dt)-X(\tau)\right|^2 &= D\left(X(t+dt)-X(t)\right) + \left(M\left|X(t+dt)-X(t)\right|^2\right) = \\
%     &= D(dt) + M(dt^2) = 0 + dt^2 \underset{dt \to 0}{\longrightarrow} 0 
% \end{align*}
\begin{align*}
    M\left|X(\tau)-X(\tau-dt)\right|^2 &= M\left|0-\{0-dt\}\right|^2 = M\left|1-dt\right|^2 = (1-dt)^2 \underset{dt \to +0}{\rightarrowx} 0
\end{align*}

Маємо розриви в точках $\tau+k$. Процес не є неперервним. Ні стохастично, ні середньоквадратично. 

Хоч він і є неперервним на інтервалах $(\tau+k, \tau+k+1)$, самі ці інтервали є випадковими. 
Отже, $X(t)$ матиме випадкові розриви.


\subsection*{2. Неперервна диференційовність}
Неперервної диференційовності бути не може, бо немає неперервності.


\section*{4}
\begin{mdframed}
    Розв'язати задачу прогнозу для стаціонарної послідовності $\{\xi_n,\;n\in\mathbb Z\}$.
    \[M\xi_n = 0; \quad \cov(\xi_n,\xi_m) = K_{nm} = a^{|n-m|}\]
    \[0<|a|<1\]
\end{mdframed}

\[K(n,m) = R(n-m); \quad R(k) = a^{|k|}.\]
Нехай $\lambda = -\ln a, \; \lambda > 0$.
Тоді 
\[R(k) = e^{-\lambda|k|}\]
Тобто, послідовність стаціонарна.

TODO


\end{document}

